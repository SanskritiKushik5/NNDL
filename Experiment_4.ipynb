{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanskritiKushik5/NNDL/blob/main/Experiment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq2e_VAYm9zE"
      },
      "source": [
        "# Experiment 4: Implementation of GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PM4JiFtmSMxR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FzmAOlSrSSNu"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxVBOr0WSiDX"
      },
      "source": [
        "Import and Preprocess the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emcoxmm_Sm7O",
        "outputId": "e733c61c-d68b-47cc-d40e-c0d9b28a24c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RPbknGNWSsJB"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5bBuU-ESvDX",
        "outputId": "2ea2803b-54da-44dc-e03c-d3c66137847b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(train_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "T6v-s8diS03t"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SHse3nPsVS2m"
      },
      "outputs": [],
      "source": [
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo_YWXnWV_t9"
      },
      "source": [
        "Build Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5hjcOxh8WCBc"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "fwZQLg_qWLSh",
        "outputId": "367caf3f-bc40-4651-e2d6-1aca8330826d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3d42029b10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBokutP0WShw",
        "outputId": "adbc7470-d20e-4376-aa97-a830881c025d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12544)             1254400   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 12544)            50176     \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 12544)             0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 7, 7, 128)        819200    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 7, 7, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 64)       204800    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        1600      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,330,944\n",
            "Trainable params: 2,305,472\n",
            "Non-trainable params: 25,472\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYbXZ1i1WbHM"
      },
      "source": [
        "Build Discriminator Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "V8Fz_Mw9Wigm"
      },
      "outputs": [],
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_1-eKkeWnze",
        "outputId": "8574d2b0-846c-4154-8800-6bfde132b026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.00287045]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hme3QbDYWopA",
        "outputId": "c3117217-b316-45e4-9b89-a79b92376645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 14, 14, 64)        1664      \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 7, 7, 128)         204928    \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 6273      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 212,865\n",
            "Trainable params: 212,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpxOS6CYWuTi"
      },
      "source": [
        "Create Custom loss functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uuLsww9qWwJA"
      },
      "outputs": [],
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8-qLdyMfW2lx"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vbRjkOzEW5oB"
      },
      "outputs": [],
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "w0CQA5TQW6a6"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OypAf_ZuXBJw"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "x1zxOQ8ZXDUx"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6KDihpoXFg9"
      },
      "source": [
        "Create the Custom Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JDauYbsxXIl7"
      },
      "outputs": [],
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "O-_BAB38XPIq"
      },
      "outputs": [],
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as you go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ICyWGKIXXVXJ"
      },
      "outputs": [],
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc9utZn-XZYg"
      },
      "outputs": [],
      "source": [
        "train(train_dataset, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "wNmeSrZ1XmgL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a1e986-b1ce-4af7-93b9-2a8d62228f10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f3d3f0ea690>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Experiment-4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPySqRq+IWLmM02PLVrBNmk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}